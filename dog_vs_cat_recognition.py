# -*- coding: utf-8 -*-
"""Dog Vs Cat Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dqUu95Y3hpFLptzM9v4ylJtVPm_lZ9GF
"""

!pip install kaggle

# Move the Kaggle API token to the required location
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

import numpy as np
import pandas as pd
from PIL import Image
import os
import cv2 as cv
import matplotlib.pyplot as plt
import tensorflow as tf
import keras as k
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout
from keras import regularizers

!kaggle datasets download -d tongpython/cat-and-dog

!unzip -q /content/cat-and-dog.zip -d /content/cat-and-dog

train_ds=k.utils.image_dataset_from_directory( directory='/content/cat-and-dog/training_set',
                                           labels='inferred',
                                           label_mode='int',
                                           batch_size=20,
                                           image_size=(256,256)
                                           )

test_ds=k.utils.image_dataset_from_directory( directory='/content/cat-and-dog/test_set',
                                           labels='inferred',
                                           label_mode='int',
                                           batch_size=20,
                                           image_size=(256,256)
                                           )

train_ds

train_ds=train_ds.shuffle(20)
test_ds=test_ds.shuffle(20)

def norm(img,label):
  n=tf.cast(img/225, tf.float32)
  return n,label

train_ds=train_ds.map(norm)
test_ds=test_ds.map(norm)

from keras.layers.attention.multi_head_attention import regularization
model=Sequential()
model.add(Conv2D(32,kernel_size=(3,3),input_shape=(256,256,3),padding='valid',kernel_regularizer=k.regularizers.l1(0.2)))
model.add(MaxPooling2D(pool_size=(3,3),strides=2))

model.add(Conv2D(64,kernel_size=(3,3),input_shape=(256,256,3),padding='valid',kernel_regularizer=k.regularizers.l2(0.2)))
model.add(MaxPooling2D(pool_size=(3,3),strides=2))

model.add(Conv2D(128,kernel_size=(3,3),input_shape=(256,256,3),activation='relu',padding='valid',kernel_regularizer=k.regularizers.l2(0.2)))
model.add(MaxPooling2D(pool_size=(3,3),strides=2))

'''model.add(Conv2D(12,kernel_size=(3,3),input_shape=(256,256,3),activation='relu',padding='valid'))
model.add(MaxPooling2D(pool_size=(3,3),strides=2))'''
Dropout(0.3)
model.add(Flatten())

model.add(Dense(16,activation='relu'))
model.add(Dense(4,activation='relu'))
#Dropout(0.3)
model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history=model.fit(train_ds,epochs=10,validation_data=test_ds)

loss_values = history.history['loss']
accuracy_values = history.history['accuracy']
val_loss_values = history.history['val_loss']
val_accuracy_values = history.history['val_accuracy']

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.show()

his=model.evaluate(test_ds)

from google.colab import drive
drive.mount('/content/drive')

dg=plt.imread('/content/drive/MyDrive/DOG.jpeg')

dg_1 = cv.resize(dg,(256,256))
dg_2=dg_1.reshape((1,256,256,3))

model.predict(dg_2)

ct=plt.imread('/content/drive/MyDrive/cat.jpg')

ct_1=cv.resize(ct,(256,256))
ct_2=ct_1.reshape((1,256,256,3))

model.predict(ct_2)

train_ds

